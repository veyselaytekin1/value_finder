{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ebay webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests    # for making standart html requests\n",
    "from bs4 import BeautifulSoup # magical tool for parsing html data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Wohnfläche': '38 m²', 'Zimmer': '1', 'Verfügbar ab': 'März 2024', 'Online-Besichtigung': 'Möglich', 'Tauschangebot': 'Kein Tausch', 'Nebenkosten': '255 €', 'Warmmiete': '980 €'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL'yi tanımlayın\n",
    "url = 'https://www.kleinanzeigen.de/s-anzeige/erstbezug-ab-sofort-donau-side-modernes-studenten-apartment-mit-fitnessstudio-co-working/2732860091-203-7613'\n",
    "\n",
    "# Sayfayı getir\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # HTTP hata durumlarını kontrol et\n",
    "\n",
    "# Sayfa içeriğini BeautifulSoup ile ayrıştır\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# \"addetailslist--detail\" sınıfına sahip tüm elementleri bul\n",
    "details = soup.find_all(class_='addetailslist--detail')\n",
    "\n",
    "# Detayları bir sözlük olarak sakla\n",
    "details_dict = {}\n",
    "\n",
    "for detail in details:\n",
    "    # İçerdeki \"addetailslist--detail--value\" sınıfına sahip değeri bul\n",
    "    detail_value_element = detail.find('span', class_='addetailslist--detail--value')\n",
    "    if detail_value_element:\n",
    "        detail_value_text = detail_value_element.get_text(strip=True)  # Değer kısmı için metin çıkarma\n",
    "        # Değeri metinden çıkararak sadece başlığı al\n",
    "        detail_title_text = detail.get_text(strip=True).replace(detail_value_text, '').strip()\n",
    "    else:\n",
    "        detail_value_text = 'Değer Yok'\n",
    "        detail_title_text = detail.get_text(strip=True)\n",
    "\n",
    "    # Başlık ve değeri sözlüğe ekle\n",
    "    details_dict[detail_title_text] = detail_value_text\n",
    "\n",
    "# Sözlüğü yazdır\n",
    "print(details_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wohnfläche: 38 m²\n",
      "Zimmer: 1\n",
      "Verfügbar ab: März 2024\n",
      "Online-Besichtigung: Möglich\n",
      "Tauschangebot: Kein Tausch\n",
      "Nebenkosten: 255 €\n",
      "Warmmiete: 980 €\n",
      "kaltmiete: 725 €\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class ApartmentScraper:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.soup = None\n",
    "\n",
    "    def fetch_page(self):\n",
    "        \"\"\"Web sayfasını çeker ve BeautifulSoup ile ayrıştırır.\"\"\"\n",
    "        response = requests.get(self.url)\n",
    "        response.raise_for_status()  # HTTP hata durumlarını kontrol et\n",
    "        self.soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    def extract_details(self):\n",
    "        \"\"\"Web sayfasından detayları çıkarır ve bir sözlük olarak döndürür.\"\"\"\n",
    "        if self.soup is None:\n",
    "            raise ValueError(\"Soup nesnesi boş. Önce fetch_page() metodunu çağırın.\")\n",
    "        \n",
    "        details = self.soup.find_all(class_='addetailslist--detail')\n",
    "        details_dict = {}\n",
    "        for detail in details:\n",
    "            detail_value_element = detail.find('span', class_='addetailslist--detail--value')\n",
    "            if detail_value_element:\n",
    "                detail_value_text = detail_value_element.get_text(strip=True)\n",
    "                detail_title_text = detail.get_text(strip=True).replace(detail_value_text, '').strip()\n",
    "            else:\n",
    "                detail_value_text = 'Değer Yok'\n",
    "                detail_title_text = detail.get_text(strip=True)\n",
    "\n",
    "            details_dict[detail_title_text] = detail_value_text\n",
    "        \n",
    "        # \"boxedarticle--flex--container\" sınıfındaki 'kaltmiete' bilgisini ekle\n",
    "        kaltmiete_element = self.soup.find(class_='boxedarticle--flex--container')\n",
    "        if kaltmiete_element:\n",
    "            kaltmiete_value = kaltmiete_element.get_text(strip=True)\n",
    "            details_dict['kaltmiete'] = kaltmiete_value\n",
    "        else:\n",
    "            details_dict['kaltmiete'] = 'Bilgi Bulunamadı'\n",
    "\n",
    "        return details_dict\n",
    "\n",
    "    def print_details(self):\n",
    "        \"\"\"Detayları yazdırır.\"\"\"\n",
    "        details = self.extract_details()\n",
    "        for title, value in details.items():\n",
    "            print(f\"{title}: {value}\")\n",
    "\n",
    "# Kullanımı\n",
    "url = 'https://www.kleinanzeigen.de/s-anzeige/erstbezug-ab-sofort-donau-side-modernes-studenten-apartment-mit-fitnessstudio-co-working/2732860091-203-7613'\n",
    "scraper = ApartmentScraper(url)\n",
    "scraper.fetch_page()\n",
    "scraper.print_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Wohnfläche': '38 m²', 'Zimmer': '1', 'Verfügbar ab': 'März 2024', 'Online-Besichtigung': 'Möglich', 'Tauschangebot': 'Kein Tausch', 'Nebenkosten': '255 €', 'Warmmiete': '980 €', 'kaltmiete': '725 €'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class ApartmentScraper:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.soup = None\n",
    "\n",
    "    def fetch_page(self):\n",
    "        \"\"\"Web sayfasını çeker ve BeautifulSoup ile ayrıştırır.\"\"\"\n",
    "        response = requests.get(self.url)\n",
    "        response.raise_for_status()  # HTTP hata durumlarını kontrol et\n",
    "        self.soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    def extract_details(self):\n",
    "        \"\"\"Web sayfasından detayları çıkarır ve bir sözlük olarak döndürür.\"\"\"\n",
    "        if self.soup is None:\n",
    "            raise ValueError(\"Soup nesnesi boş. Önce fetch_page() metodunu çağırın.\")\n",
    "        \n",
    "        details = self.soup.find_all(class_='addetailslist--detail')\n",
    "        details_dict = {}\n",
    "        for detail in details:\n",
    "            detail_value_element = detail.find('span', class_='addetailslist--detail--value')\n",
    "            if detail_value_element:\n",
    "                detail_value_text = detail_value_element.get_text(strip=True)\n",
    "                detail_title_text = detail.get_text(strip=True).replace(detail_value_text, '').strip()\n",
    "            else:\n",
    "                detail_value_text = 'Değer Yok'\n",
    "                detail_title_text = detail.get_text(strip=True)\n",
    "\n",
    "            details_dict[detail_title_text] = detail_value_text\n",
    "        \n",
    "        # \"boxedarticle--flex--container\" sınıfındaki 'kaltmiete' bilgisini ekle\n",
    "        kaltmiete_element = self.soup.find(class_='boxedarticle--flex--container')\n",
    "        if kaltmiete_element:\n",
    "            kaltmiete_value = kaltmiete_element.get_text(strip=True)\n",
    "            details_dict['kaltmiete'] = kaltmiete_value\n",
    "        else:\n",
    "            details_dict['kaltmiete'] = 'Bilgi Bulunamadı'\n",
    "\n",
    "        return details_dict\n",
    "\n",
    "# Kullanımı\n",
    "url = 'https://www.kleinanzeigen.de/s-anzeige/erstbezug-ab-sofort-donau-side-modernes-studenten-apartment-mit-fitnessstudio-co-working/2732860091-203-7613'\n",
    "scraper = ApartmentScraper(url)\n",
    "scraper.fetch_page()\n",
    "details = scraper.extract_details()\n",
    "print(details)  # Sonuçları görmek için yazdırabilirsiniz, ancak bu satırı kaldırabilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatgpt ile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detaylar listesi boş. Hiçbir veri çekilemedi.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def scrape_page(page_url):\n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def get_listing_urls(base_url, soup):\n",
    "    listing_urls = []\n",
    "    listings = soup.select('.ad-listitem')\n",
    "    for listing in listings:\n",
    "        relative_url = listing.get('data-href')\n",
    "        if relative_url:\n",
    "            full_url = base_url + relative_url\n",
    "            listing_urls.append(full_url)\n",
    "    return listing_urls\n",
    "\n",
    "def get_listing_details(listing_url):\n",
    "    soup = scrape_page(listing_url)\n",
    "    details = {}\n",
    "    price_tag = soup.find(class_='boxedarticle--price')\n",
    "    if price_tag:\n",
    "        details['price'] = price_tag.text.strip()\n",
    "    features = soup.find_all(class_='addetailslist--detail')\n",
    "    for feature in features:\n",
    "        key = feature.find(class_='addetailslist--detail--label').text.strip()\n",
    "        value = feature.find(class_='addetailslist--detail--value').text.strip()\n",
    "        details[key] = value\n",
    "    return details\n",
    "\n",
    "def scrape_all_pages(base_url, start_page, end_page):\n",
    "    all_details = []\n",
    "    for page_num in range(start_page, end_page + 1):\n",
    "        page_url = f\"{base_url}/seite:{page_num}\"\n",
    "        soup = scrape_page(page_url)\n",
    "        listing_urls = get_listing_urls(base_url, soup)\n",
    "        for url in listing_urls:\n",
    "            details = get_listing_details(url)\n",
    "            all_details.append(details)\n",
    "            print(f\"Detaylar çekildi: {details}\")  # Debugging için eklenen print\n",
    "\n",
    "    if all_details:  # Boş liste kontrolü\n",
    "        with open('rent_listings.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=all_details[0].keys())\n",
    "            writer.writeheader()\n",
    "            for details in all_details:\n",
    "                writer.writerow(details)\n",
    "    else:\n",
    "        print(\"Detaylar listesi boş. Hiçbir veri çekilemedi.\")\n",
    "\n",
    "# Ana URL ve sayfa aralığı ayarları\n",
    "BASE_URL = 'https://www.kleinanzeigen.de'\n",
    "START_PAGE = 1\n",
    "END_PAGE = 5  # Örnek olarak 5 sayfa veri çekilecek\n",
    "\n",
    "scrape_all_pages(BASE_URL, START_PAGE, END_PAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.19 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1707e2a11e748d0db8d27b6ed4dcf0f142b7ddd87c451bd8f4efb955e3e3d619"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
